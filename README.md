# Проект: Интерактивная система распознавания и генерации жестов

## Описание
Python-проект для распознавания жестов (алфавит, слова) по камере и обратного воспроизведения жестов по тексту (ролики/gif). Основано на MediaPipe, scikit-learn (KNN), PySimpleGUI.

## Установка
```
pip install -r requirements.txt
```

## Подготовка данных и обучение
1. Соберите изображения жестов по папкам: `data/samples/имя_жеста/1.png, 2.png...`
2. Запустите:
   ```
   python recognizer.py
   ```
   После успешного обучения появится файл `data/knn_model.pkl`.

## Запуск программы
1. Убедитесь, что `dictionary.json` и ролики/gif находятся в папке templates/ (`имя_жеста.mp4` или `.gif`).
2. Запустите:
   ```
   python main.py
   ```

## Использование
- Окно камеры, текущий распознанный жест — слева.
- Пробел/Enter добавляет жест в текст.
- Введите слово и нажмите "Показать жесты" — воспроизведение видео/gif по словарю.
- "Сброс" — очистка поля текста.
- "Стоп" — завершение проигрывания ролика.

## Расширение
- Добавить новые жесты: дополни dictionary.json, добавь видео/gif и обучающие изображения, переобучи модель.
- Код легко расширяется под другие классификаторы (SVM, нейросети).

## Проблемы
- Если не работает распознавание — убедись, что модель обучена и папки samples заполнены.
- Если нет видео — добавь в templates свои mp4/gif с именем жеста.
